# Default values for diracx.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

global:
  # How long should batch jobs be retained after completing?
  batchJobTTL: 600
  # TODO: To avoid being unable to launch a container when the remote registry
  # is down this should be changed to IfNotPresent once we start using tags.
  # For now we override it to Always to avoid confusion around having an
  # outdated reference to the "latest" tag.
  imagePullPolicy: Always
  # timeout for job deadlines
  activeDeadlineSeconds: 900

replicaCount: 1

image:
  repository: ghcr.io/diracgrid/diracx/server
  # Overrides the image tag whose default is the chart appVersion.
  tag: "latest"

# Created with
# kubectl create secret generic regcred \
# --from-file=.dockerconfigjson=/home/chaen/.docker/config.json \
# --type=kubernetes.io/dockerconfigjson

# imagePullSecrets:
#   - name: regcred

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000



#################

init-cs:
  # Automatically initialize the repository in the CS volume
  enabled: true
  # Users which should be automatically added to the CS
  defaultUsers: []

init-secrets:
  enabled: true
  rbac:
    create: true
  serviceAccount:
    enabled: true
    create: true
    name: # Specify a pre-existing ServiceAccount name

init-sql:
  # Should DiracX include an init container which manages the SQL DB schema?
  enabled: true
  env: {}

developer:
  enabled: true
  # Make it possible to launch the demo without having an internet connection
  offline: false
  # URLs which can be used to access various components of the demo
  urls: {}
  # Path from which to mount source of DIRACX
  sourcePath: /diracx_source
  # List of packages which are mounted into developer.sourcePath and should be installed with pip install -e
  pythonModulesToEditableInstall: []
  # List of node modules to install
  nodeModuleToInstall: null
  # Image to use for the webapp if nodeModuleToInstall is set
  nodeImage: node:16-alpine
  # Enable collection of coverage reports (intended for CI usage only)
  enableCoverage: false
  # Enable automatic reloading inside uvicorn when the sources change
  autoReload: true
  # If set, mount the CS stored localy instead of initializing a default one
  localCSPath: /local_cs_store

diracx:
  # Required: The hostname where the webapp/API is running
  # hostname:
  # Settings to inject into the API container via environment variables
  settings:
    # This corresponds to the basic dirac.cfg
    # which must be present on all the servers
    DIRACX_CONFIG_BACKEND_URL: "git+file:///cs_store/initialRepo"
    DIRACX_SERVICE_AUTH_TOKEN_KEY: "file:///signing-key/rsa256.key"
    DIRACX_SERVICE_AUTH_ALLOWED_REDIRECTS: '["http://anything:8000/docs/oauth2-redirect"]'
  # Should DiracX include an init container which manages the OS DB indices?
  manageOSIndices: true
  # Which DiracX MySQL DBs are used?
  mysqlDatabases:
    - AuthDB
    - JobDB
    - JobLoggingDB
    - SandboxMetadataDB
    - TaskQueueDB
  # Which DiracX OpenSearch DBs are used?
  osDatabases:
    - JobParametersDB
  # List of install specifications to pass to pip before launching each container
  pythonModulesToInstall: []
  # Service
  service:
    type: ClusterIP
    port: 8000

ingress:
  enabled: true
  className: "nginx"
  tlsSecretName: myingress-cert
  annotations: {}

diracxWeb:
  image:
    repository: ghcr.io/diracgrid/diracx-web/static
    tag: latest
  service:
    type: ClusterIP
    port: 8080

##########################

opensearch:
  enabled: true
  opensearchJavaOpts: "-Xms256m -Xmx256m"
  # replicas: 1
  singleNode: true
  config:
    opensearch.yml: |
      cluster.name: opensearch-cluster

      # Bind to all interfaces because we don't know what IP address Docker will assign to us.
      network.host: 0.0.0.0

      # Setting network.host to a non-loopback address enables the annoying bootstrap checks. "Single-node" mode disables them again.
      # Implicitly done if ".singleNode" is set to "true".
      # discovery.type: single-node

      # Start OpenSearch Security Demo Configuration
      # WARNING: revise all the lines below before you go into production
      plugins:
        security:
          ssl:
            transport:
              pemcert_filepath: esnode.pem
              pemkey_filepath: esnode-key.pem
              pemtrustedcas_filepath: root-ca.pem
              enforce_hostname_verification: false
            http:
              enabled: true
              pemcert_filepath: esnode.pem
              pemkey_filepath: esnode-key.pem
              pemtrustedcas_filepath: root-ca.pem
          allow_unsafe_democertificates: true
          allow_default_init_securityindex: true
          authcz:
            admin_dn:
              - CN=kirk,OU=client,O=client,L=test,C=de
          audit.type: internal_opensearch
          enable_snapshot_restore_privilege: true
          check_snapshot_restore_write_privileges: true
          restapi:
            roles_enabled: ["all_access", "security_rest_api_access"]
          system_indices:
            enabled: true
            indices:
              [
                ".opendistro-alerting-config",
                ".opendistro-alerting-alert*",
                ".opendistro-anomaly-results*",
                ".opendistro-anomaly-detector*",
                ".opendistro-anomaly-checkpoints",
                ".opendistro-anomaly-detection-state",
                ".opendistro-reports-*",
                ".opendistro-notifications-*",
                ".opendistro-notebooks",
                ".opendistro-asynchronous-search-response*",
              ]
      ######## End OpenSearch Security Demo Configuration ########
      cluster:
        routing:
          allocation:
            disk:
              threshold_enabled: "true"
              watermark:
                flood_stage: 200mb
                low: 500mb
                high: 300mb

  resources:
    requests:
      cpu: "100m"
      memory: "100Mi"

##########################


minio:
  enabled: true
  service:
    type: NodePort
  consoleService:
    type: NodePort
  ingress:
    enabled: false
  consoleIngress:
    enabled: false
  resources:
    requests:
      memory: 512Mi
  replicas: 1
  persistence:
    enabled: false
  mode: standalone
  rootUser: rootuser
  rootPassword: rootpass123
  environment:
    MINIO_BROWSER_REDIRECT_URL: http://anything:32001/

##########################

dex:
  enabled: true
  https.enabled: false

  service:
    type: NodePort
    ports:
      http:
        port: 8000
        nodePort: 32002

  ingress:
    enabled: false

  config:
    issuer: http://anything:32002

    storage:
      type: sqlite3
      config:
        file: /tmp/dex.db

    web:
      http: 8000

    expiry:
      deviceRequests: 5m
      signingKeys: 6h
      idTokens: 24h
      authRequests: 24h

    logger:
      level: "debug"
      format: text

    oauth2:
      responseTypes: [code]
      skipApprovalScreen: false
      alwaysShowLoginScreen: false

    enablePasswordDB: true

    staticClients: []
    staticPasswords: []

##########################

mysql:
  enabled: true
  auth:
    existingSecret: mysql-secret
    username: sqldiracx
    createDatabase: false
  initdbScriptsConfigMap: mysql-init-diracx-dbs

##########################

rabbitmq:
  enabled: true
  # Security context must be set to run on some k8s clusters (e.g. openshift)
  podSecurityContext:
    enabled: false
  containerSecurityContext:
    enabled: false
  auth:
    existingPasswordSecret: rabbitmq-secret
    existingErlangSecret: rabbitmq-secret

cert-manager:
  enabled: true
  installCRDs: true

cert-manager-issuer:
  enabled: true

##########################

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}
