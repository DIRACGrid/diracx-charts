# Default values for diracx.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: ghcr.io/diracgrid/diracx/server
  pullPolicy: Always
  # Overrides the image tag whose default is the chart appVersion.
  tag: "latest"

# Created with
# kubectl create secret generic regcred \
# --from-file=.dockerconfigjson=/home/chaen/.docker/config.json \
# --type=kubernetes.io/dockerconfigjson

# imagePullSecrets:
#   - name: regcred

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000



#################

init-cs:
  # Automatically initialize the repository in the CS volume
  enabled: true
  # Users which should be automatically added to the CS
  defaultUsers: []

init-secrets:
  enabled: true
  rbac:
    create: true
  serviceAccount:
    enabled: true
    create: true
    name: # Specify a pre-existing ServiceAccount name

init-sql:
  # Should DiracX include an init container which manages the SQL DB schema?
  enabled: true
  env: {}

developer:
  enabled: true
  # URLs which can be used to access various components of the demo
  urls: {}
  # Path from which to mount source of DIRACX
  sourcePath: /diracx_source
  # List of packages which are mounted into developer.sourcePath and should be installed with pip install -e
  pythonModulesToEditableInstall: []
  # List of node modules to install
  nodeModuleToInstall: null
  # Enable collection of coverage reports (intended for CI usage only)
  enableCoverage: false
  # Enable automatic reloading inside uvicorn when the sources change
  autoReload: true
  # If set, mount the CS stored localy instead of initializing a default one
  localCSPath: /local_cs_store

diracx:
  settings:
    # This corresponds to the basic dirac.cfg
    # which must be present on all the servers
    DIRACX_CONFIG_BACKEND_URL: "git+file:///cs_store/initialRepo"
    DIRACX_SERVICE_AUTH_TOKEN_KEY: "file:///signing-key/rsa256.key"
    DIRACX_SERVICE_AUTH_ALLOWED_REDIRECTS: '["http://anything:8000/docs/oauth2-redirect"]'
  # Should DiracX include an init container which manages the OS DB indices?
  manageOSIndices: true
  # Which DiracX MySQL DBs are used?
  mysqlDatabases:
    - AuthDB
    - JobDB
    - JobLoggingDB
    - SandboxMetadataDB
    - TaskQueueDB
  # Which DiracX OpenSearch DBs are used?
  osDatabases:
    - JobParametersDB
  # List of install specifications to pass to pip before launching each container
  pythonModulesToInstall: []
  ingress:
    enabled: true
    className: "nginx"
    tls: []
    hosts:
    - paths:
        - path: /api
          pathType: Prefix
          backend:
            service:
              port:
                number: 8000
        - path: /.well-known
          pathType: Prefix
          backend:
            service:
              port:
                number: 8000

diracxWeb:
  image:
    repository: ghcr.io/diracgrid/diracx-web/client
    pullPolicy: IfNotPresent
    tag: latest
  settings:
    # This corresponds to the basic .env file
    DIRACX_CLIENT_ID: "myDIRACClientID"
    DEFAULT_SCOPE: "vo:diracAdmin"
  service:
    type: ClusterIP
    port: 3000
  ingress:
    enabled: true
    className: "nginx"
    tls: []
    hosts:
    - paths:
        - path: /
          pathType: Prefix
          backend:
            service:
              port:
                number: 3000

##########################

opensearch:
  enabled: true
  opensearchJavaOpts: "-Xms256m -Xmx256m"
  # replicas: 1
  singleNode: true
  config:
    cluster.routing.allocation.disk.threshold_enabled: "true"
    cluster.routing.allocation.disk.watermark.flood_stage: 200mb
    cluster.routing.allocation.disk.watermark.low: 500mb
    cluster.routing.allocation.disk.watermark.high: 300mb
    plugins.security.disabled: "true"
  resources:
    requests:
      cpu: "100m"
      memory: "100Mi"

##########################


minio:
  enabled: true
  service:
    type: NodePort
  consoleService:
    type: NodePort
  ingress:
    enabled: false
  consoleIngress:
    enabled: false
  resources:
    requests:
      memory: 512Mi
  replicas: 1
  persistence:
    enabled: false
  mode: standalone
  rootUser: rootuser
  rootPassword: rootpass123
  environment:
    MINIO_BROWSER_REDIRECT_URL: http://anything:32001/

##########################

dex:
  enabled: true
  https.enabled: false

  service:
    type: NodePort
    ports:
      http:
        port: 8000
        nodePort: 32002

  ingress:
    enabled: false

  config:
    issuer: http://anything:32002

    storage:
      type: sqlite3
      config:
        file: /tmp/dex.db

    web:
      http: 8000

    expiry:
      deviceRequests: 5m
      signingKeys: 6h
      idTokens: 24h
      authRequests: 24h

    logger:
      level: "debug"
      format: text

    oauth2:
      responseTypes: [code]
      skipApprovalScreen: false
      alwaysShowLoginScreen: false

    enablePasswordDB: true

    staticClients: []
    staticPasswords: []

##########################

mysql:
  enabled: true
  auth:
    existingSecret: mysql-secret
    username: sqldiracx
    createDatabase: false
  initdbScriptsConfigMap: mysql-init-diracx-dbs

##########################

rabbitmq:
  enabled: true
  # Security context must be set to run on some k8s clusters (e.g. openshift)
  podSecurityContext:
    enabled: false
  containerSecurityContext:
    enabled: false
  auth:
    existingPasswordSecret: rabbitmq-secret
    existingErlangSecret: rabbitmq-secret

##########################

service:
  type: ClusterIP
  port: 8000

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}
